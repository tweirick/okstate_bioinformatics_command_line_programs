'''
@author: Tyler Weirick
@Created on: 6/18/2012 Version 0.0 
@language:Python 3.2
@tags: svm multiclass k-fold 

This program will perform k-fold testing on a given set of svm_light format 
vectors over a grid of conditions.  
'''

from sys import exit     
from glob import glob    
import os                
import subprocess        
from time import time    
from math import *       
import tempfile          
from time import asctime
import argparse




class FeaturePoint():
    """
    This class describes a point generated by some type of feature(s).
    It holds a string describing the point as well as the name of the 
    class the point is from and can return the point as a positive 
    negative or named point. 
    """
    def __init__(self,feature_line):
        assert type(feature_line) == str
        split_line = feature_line.split()
        #Make sure that a name exists.
        #@todo: make a regex to recognize proper svm format.
        assert not ":" in split_line[0],"ERROR: Point may not have name"         
        self.example_type       = split_line[0]
        self.true_class_name    = split_line[0]
        self.vector_coordiantes = " ".join(split_line[1:])
        self.predicted_class    = None
        self.value_of_pred      = None

    def getPositivepoint(self): return "+1 "+self.vector_coordiantes
    def getNegativepoint(self): return "-1 "+self.vector_coordiantes
    def getZeroPoint(self): return "0 "+self.vector_coordiantes
    def getnamedpoint(self): return self.example_type+" "+self.vector_coordiantes
        
    def updateprediction(self,class_name,value):
        assert type(class_name) == str
        assert type(value)      == float 
        if (self.predicted_class == None and self.value_of_pred == None):
            self.predicted_class   = class_name
            self.value_of_pred     = value 
        elif value > self.value_of_pred:  
            self.predicted_class   = class_name
            self.value_of_pred     = value 
                          
    def checkprediction(self,checking_class):

        if self.value_of_pred >= 0:
            if checking_class == self.true_class_name:
                if checking_class == self.predicted_class:
                    return "TP"
                else:#if self.predicted_class != self.true_class_name:
                    return "FN"
            else:#hecking_class != self.true_class_name:
                if checking_class == self.predicted_class:
                    return "FP"
                else:#if self.predicted_class != self.true_class_name:
                    return "TN"
        else:
            return "FN"
            
            

class ClassificationSet():
    """
    This class represents one class within the classification system.
    """
    def __init__(self,class_name, k, FeaturePoint_list):
        self.class_name        = class_name
        self.FeaturePoint_list = FeaturePoint_class_list
        self.k                 = k
        self.remainder         = len(class_points_list)%self.k
        self.average_length    = int(len(class_points_list)/self.k)
                   
    def getsubset(self,i):
        """
        Returns a subset 1/k of the total FeaturePoints in the FeaturePoint 
        class list. 
        """
        if i >= self.remainder:
            start+=(i-(self.remainder-1))
            stop = start+self.average_length+1
        else:
            start = self.average_length*i
            stop = start+self.average_length
            
        return self.FeaturePoint_class_list[start:stop]
    

        
class PerformanceCalculation():
        
    def __init__(self,FN,FP,TN,TP):
        self.FN = FN
        self.FP = FP
        self.TP = TP
        self.TN = TN
        
    def getaccuracy(self):
        numerator   = 100*(self.TP+self.TN)
        denominator = (self.TP+self.TN+self.FP+self.FN)
        if denominator == 0:
            return 0
        else:
            return numerator/denominator
            
    def getprecision(self):
        numerator   = 100*self.TP
        denominator = self.TP+self.FP
        if denominator == 0:
            return 0
        else:
            return numerator/denominator
        
    def getsensitivity(self):
        #{"Sensitivity":100*true_pos/(true_pos+false_neg)})
        numerator   = 100*self.TP
        denominator = self.TP+self.FN
        if denominator == 0:
            return 0
        else:
            return numerator/denominator
        
    def getspecificity(self):
        #{"Specificity":100*true_neg/(true_neg+false_pos)})
        numerator   = 100*self.TN
        denominator = self.TN+self.FP
        if denominator == 0:
            return 0
        else:
            return numerator/denominator
    
    def getMCC(self):
        #numerator = (true_pos*true_neg)-(false_pos*false_neg)
        #denominator = (true_pos+false_pos)*(true_pos+false_neg)*(true_neg+false_pos)*(true_neg+false_neg) 
        numerator   = self.TP*self.TN-self.FP*self.FN
        denominator = sqrt((self.TP+self.FP)*(self.TP+self.FN)*(self.TN+self.FP)*(self.TN+self.FN))
        if denominator == 0:
            return 0
        else:
            return numerator/denominator
    
    def geterror(self):
        #({"Error": 100*numerator/denominator })  numerator   = 100*TP
        #numerator   = (false_pos+false_neg)
        #denominator = (true_pos+true_neg+false_pos+false_neg)
        numerator   = 100*self.FP+self.FN
        denominator = (self.TP+self.TN+self.FP+self.FN)
        return numerator/denominator



#=============================================================================
#                             Functions
#=============================================================================


def getheadcomments():
    """
    This function will make a string from the text between the first and 
    second ''' encountered. Its purpose is to make maintenance of the comments
    easier by only requiring one change for the main comments. 
    """
    desc_list = []
    start_and_break = "'''"
    read_line_bool = False
    #Get self name and read self line by line. 
    for line in open(__file__,'r'):
        if read_line_bool:
            if not start_and_break in line:
                line_minus_newline = line.replace("\n","")
                space_list = []
                #Add spaces to lines less than 79 chars
                for i in range(len(line_minus_newline),80):
                     space_list.append(" ")
                desc_list.append(line_minus_newline+''.join(space_list)+"\n\r")
            else:
                break    
        if (start_and_break in line) and read_line_bool == False:
            read_line_bool = True
    desc = ''.join(desc_list)
    return desc


def getargs(ver='%prog 0.0'):
    parser = argparse.ArgumentParser(description=getheadcomments(),
        formatter_class=argparse.RawDescriptionHelpFormatter)
        
    parser.add_argument('--file_set',
                        help='A set of svm_light formatted files.')
    parser.add_argument('--k' ,
                        default=5,
                        help='The k value to test ex: 3, 5, or 10.')
    args = parser.parse_args()
    return sorted(glob(args.file_set)),int(args.k)


def dofoldclassification(c_cond,j_cond,g_cond,training_data,test_str):
    """
    
    """
    #Make the training file. 
    training_file = tempfile.NamedTemporaryFile(mode='w')  
    training_file.write(training_data)
    training_file.flush()
    
    #Make the model data into this file.
    model_file = tempfile.NamedTemporaryFile(mode='r')   
         
    #Run SVM learn svm_learn    example1/train.dat example1/model        
    #subprocess.call("free -m",shell=True)# 
    subprocess.call("./svm_learn -z c -t 2 "+
        " -c "+str(c_cond)+" -j "+str(j_cond)+" -g "+str(g_cond)+
        " "+training_file.name+" "+model_file.name,
        shell=True,stdout=open(os.devnull, 'w'))# 
    
    #Training data is no longer needed as have the model file. 
    #The file will be deleted on close.
    training_file.close()
    
    test_file = tempfile.NamedTemporaryFile(mode='w')
    test_file.write(test_str)
    test_file.flush()
    
    predictions_file = tempfile.NamedTemporaryFile(mode='r')
    #svm_classify example1/test.dat example1/model example1/predictions
    subprocess.call("./svm_classify "+test_file.name+" "+model_file.name+
        " "+predictions_file.name, shell=True,stdout=open(os.devnull, 'w'))
    
    test_file.close()
    model_file.close()#Model file no longer needed as we have predictions. 
    predictions = predictions_file.read()#open(predictions_file.name,'r')
    predictions_file.close()
    return predictions


def get_feature_classificationset_list_and_input_class_name_list(file_glob,k):
    class_name_collision_check_list = []
    feature_ClassificationSet_list  = []

    for featurized_file_with_ID in file_glob:
         #Get class name.
         class_name = featurized_file_with_ID.split(".")[0]
         feature_ClassificationSet = 
         
         if class_name in class_name_collision_check_list:
              print("ERROR Overlapping class names found:",class_name)
              exit()
         class_name_collision_check_list.append(class_name)
         
         #Add the data points in the file to ClassificationSet
         example_list = []
         for line in open(featurized_file_with_ID,"r"):
            example_list.append(FeaturePoint(line))
            
         #feature_ClassificationSet.addclasspointlist()
         #This list contains all ClassificationSet objects.
         #These should all contain the same training IDs.
         
         feature_ClassificationSet_list.append(ClassificationSet(class_name,k,example_list))
         
         print(feature_ClassificationSet.class_name,
               len(feature_ClassificationSet.FeaturePoint_class_list))
         
    assert len(class_name_collision_check_list) == len(feature_ClassificationSet_list)
    assert len(file_glob) == len(feature_ClassificationSet_list)
    return feature_ClassificationSet_list,class_name_collision_check_list



def makeconfusionmatrix(results_list,class_name_collision_check_list):
    """
    """
    confusion_matrix = {}
    for e in results_list:
        #print(type(e))
        comb = e.true_class_name.upper()+" "+e.predicted_class.upper()
        if comb in confusion_matrix:
            confusion_matrix[comb]+=1
        else:
            confusion_matrix.update({comb:1})
            
    horizontal_title = ["Class"]
    rows = []
    for class1 in sorted(class_name_collision_check_list):
        horizontal_title.append("Predicted_"+class1)
        other_stuff = ["Actual_"+class1]
        for class2 in sorted(class_name_collision_check_list):
            if class1.upper()+" "+class2.upper() in confusion_matrix:
                numb_str = str(confusion_matrix[class1.upper()+" "+class2.upper()])
            else:
                numb_str = "0"    
            #other_stuff.append(class1+"-"+class2+":"+numb_str)
            other_stuff.append(numb_str)
        rows.append(" ".join(other_stuff))
    
    return(" ".join(horizontal_title) +"\n"+"\n".join(rows))
    
    

def calculateOverallStatistics(results_list,class_name_dict):
    #results_list calc_class -> [FeaturePoint(),..]
    #print(results_list,class_name_collision_check_list)
    #Calculate Statistics need per class stats as well as overall.
    total_seqs = 0
    numerator = 0
    MCC_numerator         = 0
    accuracy_numerator    = 0
    precision_numerator   = 0
    sensitivity_numerator = 0
    specificity_numerator = 0
    error_numerator       = 0
    total_FN = 0
    total_FP = 0
    total_TN = 0
    total_TP = 0
    for class_name in class_name_collision_check_list:
        number_of_seqs_per_class = 0
        osd = {"TP":0,"TN":0,"FP":0,"FN":0}
        for e in results_list:
            if e.true_class_name.upper() == class_name.upper():
                number_of_seqs_per_class+=1     
            osd[e.checkprediction(class_name)]+=1    
        pc = PerformanceCalculation(osd["FN"],osd["FP"],osd["TN"],osd["TP"])
        
        total_seqs+=number_of_seqs_per_class
      
        MCC_numerator         += number_of_seqs_per_class*pc.getMCC()
        accuracy_numerator    += number_of_seqs_per_class*pc.getaccuracy()  
        precision_numerator   += number_of_seqs_per_class*pc.getprecision()
        sensitivity_numerator += number_of_seqs_per_class*pc.getsensitivity()
        specificity_numerator += number_of_seqs_per_class*pc.getspecificity()
        error_numerator       += number_of_seqs_per_class*pc.geterror()
        total_FN += osd["FN"]
        total_FP += osd["FP"]
        total_TN += osd["TN"]
        total_TP += osd["TP"]



    out_list = [asctime(),"c="+str(c_cond)+" j="+str(j_cond)+" g="+str(g_cond)+
                    " MCC="+str(MCC_numerator/total_seqs)+
                    " accuracy="+str(accuracy_numerator/total_seqs)+
                    " precision="+str(precision_numerator/total_seqs)+
                    " sensitivity="+str(specificity_numerator/total_seqs)+
                    " specificity="+str(error_numerator/total_seqs)+
                    " error="+str(performance_dict["error"])+
                    " FN="+str(total_FN)+
                    " FP="+str(total_FP)+
                    " TN="+str(total_TN)+
                    " TP="+str(total_TP)+
                    " total_seqs="+str(total_seqs)+"\n"]

    return out_cals
    
    


def getdictofclassnameandFeaturePointlist(sorted_file_glob):
    """
    This function generates a dict with the keys made of class names and the 
    values made of lists of FeaturePoint classes. It will also do basic data
    validation.
    1. Individual vectors and class names taken from the file names match.  
    2. Each file contains only one vector type.
    3. No overlaps in class names exist.
    """
    
    vector_class_dict = {}
    for featurized_file_with_ID in sorted_file_glob:
        
         #Get class name.
         class_name = featurized_file_with_ID.split(".")[0]
         
         #Ensure class names do not overlap.
         assert not class_name in vector_class_dict,(
             "ERROR: two classes have the same name.")
              
         #Add the data points in the file to ClassificationSet
         example_list = []
         for line in open(featurized_file_with_ID,"r"):
            #Ensure only on class per vector file.        
            line_class_name = line.split()[0]
            if example_list != []: assert last_line_name == line_class_name
            
            #Add a FeaturePoint class. These classes help with interpreting the
            #results of classification. 
            example_list.append(FeaturePoint(line))
            
            #Ensure no classes have the same name. 
            last_line_name = line_class_name
            assert last_line_name == class_name,("ERROR:Class and vector"+
                " name do not match."+last_line_name+" != "+class_name)
            
         #Add to a dict for later use. 
         vector_class_dict.update({class_name:ClassificationSet(class_name,example_list,k)})
                    
    #Ensure the input and number of ClassificationSet objects are equal.
    assert len(sorted_file_glob) == len(vector_class_dict)
    return vector_class_dict



def generateSVMtraingingdatastring(training_data):
    """
    INPUT : A list containing FeaturePoint classes
    OUTPUT: A string with (1|-1) and a vector (ex:1:0.343...) per line.
    
    This function generates a string that will be written to a file 
    that will be used as training data for the support vector machine. 
    """
    ex = []
    for example in training_data:
        if example.example_type == class_name:
            ex.append(example.getPositivepoint())
        else:
            ex.append(example.getNegativepoint())
    return "\n".join(ex)#PlusMinusFile


def dokfoldtestat(k,c,j,g,vec_class_dict):   
    """
    
    """
              
    results_list = [] 
    #Test a fold:
    #Make a k-1/k training set of the input data and a 1/k testing set.
    for k_level in range(0,k):
    
        training_data        = []
        calc_data            = []
    
        #If not equal to k than add to k-1/k training set. 
        for fold_n in range(0,k):
            for classifer in vector_class_dict:
                if k_level == fold_n:
                    calc_data = calc_data + vec_class_dict[classifer].getsubset(fold_n)
                else:
                    #Get level k for each protein class.       
                    training_data = training_data + vec_class_dict[classifer].getsubset(fold_n)
    
        test_data = []
        for name_point in calc_data:
            test_data.append(e.getnamedpoint())
        test_str = "\n".join(test_data)
    
        plus_minus_data_list = []
        for class_name in class_name_collision_check_list:
            #for n class_types make plus negative files.
            #Will need to make one for every class. 
            print("Start Classification.",class_name,"c",c,"j",j,"g",g,"time",time())
            
            i = 0
                    
            training_data_str = generateSVMtraingingdatastring(training_data)
                
            predictions = dofoldclassification(c,j,g,training_data_str,test_str)
            
            for line in predictions.split("\n"):
                #There will be one floating point number for each line. 
                calc_data[i].updateprediction(class_name,float(line.strip()))#calc_data[i].class_value_dict.update({class_name:line.strip()})
                i+=1
    
            #Ensure that no lines have been left out of prediction.    
            assert i == len(calc_data)
            
            #Add the results from the round to the overall results. 
            results_list = results_list + calc_data
            print("Classification Complete.",time())
    return results_list



#=============================================================================
#                             Variables
#=============================================================================

#Runtime parameters for SVM, iterated over for grid search.    
c_start,c_end,c_parts = 0.1,500,7
j_start,j_end,g_parts = 1,15,7
g_start,g_end,j_parts = 1,500,4
c_increment = (c_end-c_start)/c_parts
j_increment = (j_end-j_start)/j_parts
g_increment = (g_end-g_start)/g_parts

#Holds the best MCC found. 
max_mcc = 0.0

#Keep track of the start time of the script to keep additional runs from overlapping. 
start_time    = str(int(time()))

#The base name to be used in output files. 
out_base_name = args.file_set.replace("*","")+"_"+start_time


#=============================================================================
#                             Main Program
#=============================================================================

#Get command line arguments. 
# sorted_file_glob - List of files containing the vector files for testing.
# k                - The number(as integer) of folds to use in testing.  
sorted_file_glob,k  = getargs()

#Must have more than one class to classify something.  
assert len(sorted_file_glob) > 1,"Must have two or more files for classification."

print(len(sorted_file_glob),"files received for",str(k)+"-fold classification.")
print("Files received:")
print("\n".join(sorted_file_glob))

#Get dict containing class names as keys and lists of FeaturePoint classes
#as the values. 
vec_class_dict = getdictofclassnameandFeaturePointlist(sorted_file_glob)

#The previous function validates the following error conditions. 
print("\nClass names from file names and vector names match. True")
print("\nEach files contains only one vector type.           True")
print("No overlaps in class names.                           True\n")


for g_int in range(1,g_parts+1):
    g = g_int*g_increment
    if g == 0: g=0.1
    for c_int in range(0,c_parts+1):
        c = c_int*c_increment
        if c == 0:c=0.1
        for j_int in range(0,j_parts+1):
            j = j_int*j_increment
            if j == 0: j =0.1
            
            print("Classifying with variables","c = ",c,"j = ",j,"g = ",g)   
            
            #Perform an entire k-fold test
            results_list = dokfoldtestat(k,c,j,g,vec_class_dict)
            
            #Get the performance statistics of the k fold test.             
            performance_stats_str = calculateOverallStatistics(results_list,vec_class_dict)
                        
            if max_mcc < performance_dict["mcc"]:
                #Set new max MCC.
                max_mcc = performance_dict["mcc"]
    
                file = open("training_best_stats"+out_base_name+".posvalonly.txt",'w')
                file.write("\n".join(out_list))
                file.close()

                file = open("best_stats_confusion_matrix"+out_base_name+".posvalonly.txt",'w')
                file.write(makeconfusionmatrix(results_list,class_name_collision_check_list))
                file.close()
                
            #append run history to logfile. 
            #Time conditions MCC
            file = open("training_history"+out_base_name+".txt",'a')
            file.write(",".join(out_list))
            file.close()
0
